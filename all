import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn import svm
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

# Load the Titanic dataset
titanic_df = pd.read_csv('titanic.csv')

# One-hot encode 'Sex' and 'Embarked' columns
sex_dummies = pd.get_dummies(titanic_df['Sex'])
sex_dummies = sex_dummies[['male', 'female']].replace({True : 1, False : 0})
embarked_dummies = pd.get_dummies(titanic_df['Embarked'])
embarked_dummies = embarked_dummies[['C', 'Q', 'S']].replace({True : 1, False : 0})

# Drop unnecessary columns and concatenate one-hot encoded columns
titanic_df = titanic_df.drop(columns=['Name', 'Ticket', 'Cabin', 'Sex', 'Embarked', 'PassengerId'])
titanic_df = pd.concat([titanic_df, sex_dummies, embarked_dummies], axis=1)

# Function to fill missing 'Age' values based on 'Pclass'
def fill_age(age, pclass):
    if pd.isnull(age):
        if pclass == 1:
            return 38
        elif pclass == 2:
            return 30
        else:
            return 25
    else:
        return age

# Apply the function to fill missing 'Age' values
titanic_df['Age'] = titanic_df.apply(lambda row: fill_age(row['Age'], row['Pclass']), axis=1)

# Split dataset into features (X) and target (y)
features = titanic_df.drop(columns=['Survived'])
target = titanic_df['Survived']

# Split data into train and test sets
features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=42)

# Standardize features
scaler = StandardScaler()
features_train_scaled = scaler.fit_transform(features_train)
features_test_scaled = scaler.transform(features_test)

# Logistic Regression
logistic_model = LogisticRegression()
logistic_model.fit(features_train_scaled, target_train)
logistic_predictions = logistic_model.predict(features_test_scaled)
logistic_accuracy = accuracy_score(logistic_predictions, target_test)
print("Logistic Regression Accuracy score - ", logistic_accuracy)

# Support Vector Machine
svm_model = svm.SVC(kernel='linear', C=7, degree=1)
svm_model.fit(features_train_scaled, target_train)
svm_predictions = svm_model.predict(features_test_scaled)
svm_accuracy = accuracy_score(svm_predictions, target_test)
print("SVM Accuracy score - ", svm_accuracy)

# Decision Tree Classifier
tree_model = DecisionTreeClassifier()
tree_model.fit(features_train_scaled, target_train)
tree_predictions = tree_model.predict(features_test_scaled)
tree_accuracy = accuracy_score(tree_predictions, target_test)
print("Decision Tree Accuracy Score - ", tree_accuracy)
